best)
data <- ged241 |>
filter(conflict_name == "Israel: Palestine" & country == "Israel") |>
select(year, side_b, adm_1, latitude, longitude, event_clarity, date_prec,
date_start, date_end, deaths_a, deaths_b, deaths_civilians,
deaths_unknown, best)
rm(list = ls())
# caricamento librerie
if(!require(tidyverse)) install.packages("tidyverse")
ged241 <- readRDS("ged241.rds")
data <- ged241 |>
filter(conflict_name == "Israel: Palestine" & country == "Israel") |>
select(year, side_b, adm_1, latitude, longitude, event_clarity, date_prec,
date_start, date_end, deaths_a, deaths_b, deaths_civilians,
deaths_unknown, best)
data$event_duration <- as.numeric((data$date_end - data$date_start)/(3600*24))
date_start <- data$date_start
date_start <- as.Date(date_start, format = "%Y-%m-%d")
days_since_start <- as.numeric(date_start - min(date_start))
data$days_since_start <- days_since_start
data$intertimes <- c(NA, diff(data$days_since_start))
write.csv(data, "IS_PAL.csv")
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
# Salvataggio dati in un csv
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
w_isr
View(w_isr)
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
data <- read.csv("IS_PAL.csv")
head(data)
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = c, .packages = "base") %dopar% {
# Initialize variables within the loop
distance_from_i <- numeric(nrow(w_isr))
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
# Compute distances for all rows in 'w_isr'
for (j in 1:nrow(w_isr)) {
xy_j <- as.numeric(w_isr[j, , drop = TRUE])
distance_from_i[j] <- sum((xy_i - xy_j)^2)
}
# Return the index of the minimum distance
which.min(distance_from_i)
}
# Stop the parallel backend
stopCluster(cl)
i <- 1
distance_from_i <- numeric(nrow(w_isr))
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
xy_i
# Extract coordinates for the i-th row of 'data'
xy_i <- data[i, c("latitude", "longitude")]
xy_i
colnames(w_isr)
xy_i - w_isr[, c("Latitude", "Longitude")]
# Extract coordinates for the i-th row of 'data'
xy_i <- data[i, c("latitude", "longitude"), drop = T]
xy_i
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
xy_i
xy_i - w_isr[, c("Latitude", "Longitude")]
w_isr[1, c("Latitude", "Longitude")]
xy_i
(31.90256-32.71094)^2 + (35.19555-35.57086)^2
sqrt((31.90256-32.71094)^2 + (35.19555-35.57086)^2)
xy_i
(xy_i-w_isr[1, c("Latitude", "Longitude")])^2
sqrt((31.90256-32.71094)^2 + (35.19555-35.57086)^2)
sqrt((xy_i-w_isr[1, c("Latitude", "Longitude")])^2)
sum(sqrt((xy_i-w_isr[1, c("Latitude", "Longitude")])^2))
sqrt((31.90256-32.71094)^2 + (35.19555-35.57086)^2)
sqrt((31.90256-32.71094)^2 + (35.19555-35.57086)^2)
w_isr[1, c("Latitude", "Longitude")]
sum(sqrt((xy_i-w_isr[1, c("Latitude", "Longitude"), drop = T])^2))
sum(sqrt((xy_i-as.matrix(w_isr[1, c("Latitude", "Longitude")]))^2))
sqrt((31.90256-32.71094)^2 + (35.19555-35.57086)^2)
xy_i
xy_j <- w_isr[, c("Latitude", "Longitude")]
xy_j
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
xy_j
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
xy_i
xy_i - xy_j
(xy_i - xy_j)[1, ]
xy_i[1] - xy_j[1, 1]
xy_i[2] - xy_j[1, 2]
(t(xy_i) - xy_j)[1, ]
t(xy_i)
xy_j
apply(xy_j, 1, function(xyj) xy_i - xy_j)
xy_i
xy_j
View(apply(xy_j, 1, function(xyj) xy_i - xy_j))
xy_j
xy_j - xy_i
matrix(c(0,0), nrow = 5, ncol = 2)
?sweep
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
xy_i
xy_j
result <- sweep(xy_j, 2, xy_i, "-")
result
result[1, ]
result[1, ]
xy_i[1] - xy_j[1, 1]
xy_j[1, 1] - xy_i[1]
xy_j[1, 2] - xy_i[1]
result[1, ]
xy_j[1, 2] - xy_i[2]
k <- 2
result[k, ]
xy_j[k, 1] - xy_i[1]
xy_j[k, 2] - xy_i[2]
k <- 3
result[k, ]
xy_j[k, 1] - xy_i[1]
xy_j[k, 2] - xy_i[2]
result
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2))
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
distance_from_i
rm(list = ls())
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
# Salvataggio dati in un csv
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
i <- 1
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
xy_i
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
distance_from_i
?sweep
sweep(xy_j, 2, xy_i, "-")
sweep(xy_j, 2, xy_i, "-")
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
distance_from_i
View(distance_from_i)
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
which.min(distance_from_i)
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
which.min(distance_from_i)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = list, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
?foreach
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
# Salvataggio dati in un csv
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
# Stop the parallel backend
stopCluster(cl)
min_distance_from_i
nrow(min_distance_from_i)
?foreach
rownames(min_distance_from_i) <- NULL
head(min_distance_from_i)
# Salvataggio dati in un csv
head(filtered_places2)
# Salvataggio dati in un csv
rownames(filtered_places2) <- NULL
head(filtered_places2)
View(filtered_places2)
filtered_places2$id <- 1:nrow(filtered_places2)
head(filtered_places2)
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
View(w_isr)
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
xy_j
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
# Stop the parallel backend
stopCluster(cl)
nrow(min_distance_from_i)
rownames(min_distance_from_i) <- NULL
min_distance_from_i
head(data)
rm(list = ls())
# caricamento librerie
if(!require(tidyverse)) install.packages("tidyverse")
ged241 <- readRDS("ged241.rds")
ged241
colnames(ged241)
rm(list = ls())
# caricamento librerie
if(!require(tidyverse)) install.packages("tidyverse")
ged241 <- readRDS("ged241.rds")
data <- ged241 |>
filter(conflict_name == "Israel: Palestine" & country == "Israel") |>
select(id, year, side_b, adm_1, latitude, longitude, event_clarity, date_prec,
date_start, date_end, deaths_a, deaths_b, deaths_civilians,
deaths_unknown, best)
data$event_duration <- as.numeric((data$date_end - data$date_start)/(3600*24))
date_start <- data$date_start
date_start <- as.Date(date_start, format = "%Y-%m-%d")
days_since_start <- as.numeric(date_start - min(date_start))
data$days_since_start <- days_since_start
data$intertimes <- c(NA, diff(data$days_since_start))
write.csv(data, "IS_PAL.csv")
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
points2
View(points2)
# Salvataggio dati in un csv
rownames(filtered_places2) <- NULL
head(filtered_places2)
filtered_places2$id <- 1:nrow(filtered_places2)
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
# Stop the parallel backend
stopCluster(cl)
nrow(min_distance_from_i)
rownames(min_distance_from_i) <- NULL
head(min_distance_from_i)
min_distance_from_i <- as.data.frame(min_distance_from_i)
head(min_distance_from_i)
colnames(min_distance_from_i) <- c("nearest_pow", "dist_nearest_pow")
head(min_distance_from_i)
min_distance_from_i$id <- data$id
head(min_distance_from_i)
head(data[, 1:3])
?merge
merge(data, min_distance_from_i, by = id)
merge(data, min_distance_from_i, by = "id")
head(merge(data, min_distance_from_i, by = "id"))
head(min_distance_from_i)
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
# Salvataggio dati in un csv
rownames(filtered_places2) <- NULL
filtered_places2$id <- 1:nrow(filtered_places2)
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
# Stop the parallel backend
stopCluster(cl)
nrow(min_distance_from_i)
rownames(min_distance_from_i) <- NULL
min_distance_from_i <- as.data.frame(min_distance_from_i)
head(min_distance_from_i)
colnames(min_distance_from_i) <- c("nearest_pow", "dist_nearest_pow")
min_distance_from_i$id <- data$id
head(min_distance_from_i)
data
head(data)
nrow(data)
nrow(min_distance_from_i)
head(min_distance_from_i)
head(min_distance_from_i)
head(merge(data, min_distance_from_i, by = "id"))
cbind(data, min_distance_from_i)
head(cbind(data, min_distance_from_i))
View((cbind(data, min_distance_from_i))
)
data$id
min_distance_from_i$id
min_distance_from_i$id == data$id
all(min_distance_from_i$id == data$id)
rm(list = ls())
library(osmdata)
library(sf)
library(tidyverse)
# Definisci l'area geografica (esempio: Israele)
area2 <- "Israel"
# Query per luoghi di culto
places_of_worship_i <- opq(bbox = area2) |>
add_osm_feature(key = "amenity", value = "place_of_worship") |>
osmdata_sf()
# Estrai i dati dei punti (nodi)
points2 <- places_of_worship_i$osm_points |>
select(name, geometry) |>
mutate(Latitude = st_coordinates(geometry)[,2],
Longitude = st_coordinates(geometry)[,1]) |>
st_drop_geometry() # Rimuove la colonna geometrica, se non necessaria
# Rimuovi i punti senza nome
filtered_places2 <- points2 |>
filter(!is.na(name)) |>
select(Name = name, Latitude, Longitude)
# Salvataggio dati in un csv
rownames(filtered_places2) <- NULL
filtered_places2$id <- 1:nrow(filtered_places2)
write.csv(filtered_places2, "places_of_worship_israel.csv", row.names = FALSE)
w_isr <- read.csv("places_of_worship_israel.csv")
data <- read.csv("IS_PAL.csv")
xy_j <- as.matrix(w_isr[, c("Latitude", "Longitude")])
library(foreach)
library(doParallel)
# Set up the parallel backend
num_cores <- round(parallel::detectCores()/2)
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Parallel computation with foreach
min_distance_from_i <- foreach(i = 1:nrow(data), .combine = rbind, .packages = "base") %dopar% {
# Extract coordinates for the i-th row of 'data'
xy_i <- as.numeric(data[i, c("latitude", "longitude")])
distance_from_i <- apply(sweep(xy_j, 2, xy_i, "-"), 1, function(x) sum(sqrt(x^2)))
# Return the index of the minimum distance
c(which.min(distance_from_i), min(distance_from_i))
}
# Stop the parallel backend
stopCluster(cl)
nrow(min_distance_from_i)
rownames(min_distance_from_i) <- NULL
min_distance_from_i <- as.data.frame(min_distance_from_i)
head(min_distance_from_i)
colnames(min_distance_from_i) <- c("nearest_pow", "dist_nearest_pow")
head(min_distance_from_i)
data.frame(data, min_distance_from_i)
data <- data.frame(data, min_distance_from_i)
write.csv(data, "IS_PAL.csv")
head(read.csv("IS_PAL.csv"))
head(min_distance_from_i)
write.csv(min_distance_from_i, "nearest_pow.csv")
data <- data.frame(data, min_distance_from_i)
